# Classifying Local News Television Transcripts Using RoBERTa

Local television news is one of Americansâ€™ most common news sources, but its content has received minimal study compared with its cable and digital counterparts. Relevant local information is necessary for citizens to cast informed votes in local elections. We amassed a novel dataset of approximately 18,000 closed captioning transcripts from local television news programs, which we divided into over 600,000 one-minute segments. We fine-tune seven RoBERTa models to detect common topics in local television news. These classifiers allow us to estimate the amount of attention devoted to different news topics by local television news programs and how the focus of local television news has changed over time. As far as we are aware, our project is the first to implement a transformer-based architecture (i.e., RoBERTa) to study local television news content. As such, our primary contributions are in application and data. Across seven classification topics, we find the series of RoBERTa models achieved an average precision score of 0.85, an average recall score of 0.876, and an average F1 score of 0.859.
